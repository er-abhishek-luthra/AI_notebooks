---
title: 1. State-action value function
tags: [blog]
publish: true
---

# State-action value function

In this module, we explore one of the foundational ideas in reinforcement learning — the **state-action value function**, often referred to as the **Q-function**.

The **Q-function**, denoted as $Q(s, a)$, represents the expected return if you:
- start in state $s$
- take action $a$ (once)
- then behave **optimally** after that

This might seem a bit circular at first — if we already know what optimal behavior is, why compute $Q(s, a)$? But don't worry — we'll see later how to compute the Q-function even before we know the optimal policy.

Let’s look at the **Mars rover** example to make this concrete.

![Q-function defined with an example](_resources/q-function-definition.png)

### Examples:

- $Q(2, \rightarrow) = 0 + (0.5)\cdot0 + (0.5)^2\cdot0 + (0.5)^3\cdot100 = 12.5$
- $Q(2, \leftarrow) = 0 + (0.5)\cdot100 = 50$
- $Q(4, \leftarrow) = 0 + (0.5)\cdot0 + (0.5)^2\cdot0 + (0.5)^3\cdot100 = 12.5$

This means if you're in state 2 and take action right, and then behave optimally, the expected return is 12.5. If you go left instead, you reach the terminal state faster, with an expected return of 50.

This leads to a useful insight:

- $Q(s, a)$ doesn't **judge** whether the action is good — it simply tells you what return you'd get **if** you took it and behaved optimally afterward.

Once we have $Q(s, a)$ values for each state and action, we can derive the **optimal policy**:

![Using Q-values to pick optimal actions](_resources/picking-optimal-actions.png)

We define the **optimal policy** $\pi(s)$ as:

$$
\pi(s) = \underset{a}{\text{argmax}}\ Q(s, a)
$$

This means in each state $s$, choose the action $a$ that maximizes $Q(s, a)$.

### Summary

- $Q(s, a)$ tells us how good an action is in a given state if we behave optimally afterward.
- Once we know $Q(s, a)$ for all states and actions, we can define the optimal policy $\pi(s)$.
- This makes computing the Q-function central to reinforcement learning algorithms.

You may also encounter $Q^*(s, a)$ or just $Q^*$ in literature — this is just another way of denoting the **optimal Q-function**.
